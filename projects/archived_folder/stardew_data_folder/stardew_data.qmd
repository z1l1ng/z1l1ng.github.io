---
title: "Stardew Valley Data Acquisition"
author: "Ziling Zhen & Rain Hartos"
date: "2024-12-02"
sidebar: false
format:
  html:
    code-fold: true
image: stardewmap.png
editor_options: 
  chunk_output_type: console
freeze: true
---

```{r, include = FALSE}
library(tidyverse)
library(stringr)
library(rvest)
library(polite)
library(viridis)
library(htmltools)
library(janitor)
library(httr2)
library(httr)
library(lubridate)
library(purrr)
library(kableExtra)
library(sf)
library(raster)
library(ggimage)
```


## Introduction

For our project, we decided to scrape data from the wiki pages of one of our favorite video games, *Stardew Valley*. *Stardew Valley* is a popular indie farming game that allows players to take on the role of a character who inherits a run-down farm from their grandfather. In the game, players can grow crops, raise animals, fish, mine, and engage in social activities with the towns people.

For our project, we were interested in compiling a list of items from the game that can be farmed or collected. The only way to make money from the game is by selling these items, and the price of the item depends on the quality of the item and the profession(s) of the player. Thus, our dataset includes information on the name, category, subcategory, and the different price points of the item depending on item quality (regular, silver, gold, and iridium) and player's profession.

## Approach

All of our data has been accumulated from the [*Stardew Valley* Wiki](https://stardewvalleywiki.com/Stardew_Valley_Wiki) page. Since each item in the game has a different page and not all of the pages followed a similar structure, we used a combination of harvesting the data in both table form and anywhere on the webpage using rvest with html_text. In the end, we were able to create a dataset from the more important item categories: crops, fish, animal products, and minerals.

### Crops

Crops was the most difficult item to scrape from the wiki, since not all of the pages are structured the same. However, we tried our best to automate where we could.

We start be getting a list of all the different crops in the game.

```{r}
#check that we are allowed to scrape the wiki
robotstxt::paths_allowed("https://stardewvalleywiki.com/Stardew_Valley_Wiki")

session <- bow("https://stardewvalleywiki.com/Stardew_Valley_Wiki", force = TRUE)

# scrape crops page
crops <- bow("https://stardewvalleywiki.com/Crops", force = TRUE)

result <- scrape(crops) |>
  html_nodes(css = "table") |>
  html_table(header = TRUE, fill = TRUE)

seasonal_crops <- result[[134]][2] #table of the season crops so we can use that list

seasonal_crops <- seasonal_crops |>
  mutate(Crops = strsplit(Crops, " • ", fixed = TRUE)) |>
  unnest(Crops) |>
  mutate(Crops = str_replace_all(Crops, " ", "_")) |>
  distinct(Crops)
```

Create our helper functions for crops:

```{r}
# function for getting the price at a given page and css selector
get_price <- function(page, css_selector) {
  page |>
  html_nodes(css_selector) |>
  html_text()
}

# function for creating a tibble of base prices, no profession, for a given crop page
crop_base_prices <- function(crop, tiller = FALSE) {
  url <- str_c("https://stardewvalleywiki.com/", crop)
  page <- read_html(url)
  
  qualities <- c("regular", "silver", "gold", "iridium")
  prices <- list()
  
  for (i in seq_along(qualities)) {
    if (tiller) {
      selector <- str_c("tr:nth-child(10) td+ td tr:nth-child(", i, ") td+ td")
    } else {
      selector <- str_c("tr:nth-child(10) tr td:nth-child(1) tr:nth-child(", i, ") td+ td")
    }
    price <- get_price(page, selector)
    prices[[qualities[i]]] <- parse_number(price)
  }
  
  tibble(
    item = crop,
    regular_price = prices$regular,
    silver_price = prices$silver,
    gold_price = prices$gold,
    iridium_price = prices$iridium
  )
}

```

Create the tibbles for seasonal crops using the helper functions. Note that items 46 (Tea_Leaves), 44 (Sweet Gem Berry), 43 (Qi_Fruit), 41 (Cactus_Fruit), 36 (Grape), 4 (Coffee_Bean) have issues when using the functions, so we will scrape the data manually without the functions.

```{r}
# list of all our seasonal crops
seasonal_crops_list <- pull(seasonal_crops) # list of our crops tibble

# list of crops, excluding those with known issues
valid_crops_list <- seasonal_crops_list[-c(46, 44, 43, 41, 36, 4)]

# base prices without profession
base_crop_prices <- valid_crops_list |>
  purrr::map_dfr(~ crop_base_prices(.x)) |>
  mutate(profession = as.character(NA))

# prices with Tiller profession
tiller_crop_prices <- valid_crops_list |>
  purrr::map_dfr(~ crop_base_prices(.x, tiller = TRUE)) |>
  mutate(profession = "tiller")

# combine base and tiller crop prices
seasonal_crop_prices <- bind_rows(base_crop_prices, tiller_crop_prices)
```

Do the same for non seasonal crops:

```{r}
# non-seasonal crops list, excluding problematic items
other_crops <- c("Apple", "Blackberry", "Pomegranate", "Wild_Plum", "Apricot", 
                 "Cherry", "Spice_Berry", "Peach", "Orange", "Crystal_Fruit", 
                 "Banana", "Mango", "Fiddlehead_Fern")[-c(10, 7, 4, 2)]

# base prices without profession
base_other_crops <- other_crops |>
  purrr::map_dfr(~ crop_base_prices(.x)) |>
  mutate(profession = as.character(NA))

# prices with Tiller profession
tiller_other_crops <- other_crops |>
  purrr::map_dfr(~ crop_base_prices(.x, tiller = TRUE)) |>
  mutate(profession = "tiller")

# combine base and tiller prices into one table and arrange by item
nonseasonal_crop_tbl <- bind_rows(base_other_crops, tiller_other_crops) |>
  arrange(item)
```

Finally, create a function for the weird crops that have missing quality or selector path was different

```{r}
# function for the crops that do not have different qualities
crop_weird_prices <- function(item, selector){
  url <- str_c("https://stardewvalleywiki.com/", item)
  page <- read_html(url)
  regular_price <- get_price(page, selector)
  
  tibble(item = item,
      regular_price = parse_number(regular_price))
}

# function for the crops that have different qualities. the Berry is for the fruits that have a weird selector that seems to follow a similar pattern.
crop_weird_prices_w_quality <- function(crop, tiller = FALSE, berry = FALSE ){
  url <- str_c("https://stardewvalleywiki.com/", crop)
  page <- read_html(url)
  
  qualities <- c("regular", "silver", "gold", "iridium")
  prices <- list()
  
  for (i in seq_along(qualities)) {
    if (tiller) {
      selector <- str_c("tr:nth-child(11) td+ td tr:nth-child(", i, ") td+ td")
    } else if (berry){
      selector <- str_c("tr:nth-child(9) tr:nth-child(", i, ") td+ td")
    }else {
      selector <- str_c("tr:nth-child(11) tr td:nth-child(1) tr:nth-child(", i, ") td+ td")
    }
    price <- get_price(page, selector)
    prices[[qualities[i]]] <- parse_number(price)
  }
  
  tibble(
    item = crop,
    regular_price = prices$regular,
    silver_price = prices$silver,
    gold_price = prices$gold,
    iridium_price = prices$iridium
  )
}

```

Now we make all of the tibbles for the weird crops.

```{r}
# tea leaves
base_tea_leaves <- crop_weird_prices("Tea_Leaves",
                                     "tr:nth-child(10) tr td:nth-child(1) td+ td")

tiller_tea_leaves <- crop_weird_prices("Tea_Leaves",
                                     "tr:nth-child(10) td+ td td+ td")

tea_leaves <-bind_rows(base_tea_leaves, tiller_tea_leaves)

# qi fruit
base_qi_fruit <-crop_weird_prices("Qi_Fruit",
                                  "tr:nth-child(9) tr td:nth-child(1) td+ td")

tiller_qi_fruit <-crop_weird_prices("Qi_Fruit",
                                  "tr:nth-child(9) td+ td td+ td")

qi_fruit <-bind_rows(base_qi_fruit, tiller_qi_fruit)

# cactus fruit
cactus_fruit <- crop_weird_prices_w_quality("Cactus_Fruit")

cactus_fruit_tiller <- crop_weird_prices_w_quality("Cactus_Fruit", tiller = TRUE)

cactus_fruit <-bind_rows(cactus_fruit, cactus_fruit_tiller)

# grape
grape <- crop_weird_prices_w_quality("Grape")

grape_tiller <- crop_weird_prices_w_quality("Grape", tiller = TRUE)

grape <-bind_rows(grape, grape_tiller)

# coffee bean
coffee_bean <- crop_weird_prices_w_quality("Coffee_Bean")

# wild plum
wild_plum <- crop_weird_prices_w_quality("Wild_Plum", berry = TRUE)

# spice berry
spice_berry <- crop_weird_prices_w_quality("Spice_Berry", berry = TRUE)

# crystal fruit
crystal_fruit <- crop_weird_prices_w_quality("Crystal_Fruit", berry = TRUE)

# Finally, blackberry is just weird and likes to be different, so we did not use a function for it. 
#Blackberry

# base
url <- str_c("https://stardewvalleywiki.com/", "Blackberry")
page <- read_html(url)

qualities <- c("regular", "silver", "gold", "iridium")
prices <- list()

# loop to retrieve and parse prices
for (i in seq_along(qualities)) {
  price <- get_price(page, str_c("tr:nth-child(9) tr td:nth-child(1) tr:nth-child(", i, ") td+ td"))
  prices[[qualities[i]]] <- parse_number(price)
}

blackberry <- tibble(
  item = "Blackberry",
  regular_price = prices$regular,
  silver_price = prices$silver,
  gold_price = prices$gold,
  iridium_price = prices$iridium
)

```

Now, we can combine all of the crop tibbles into one:

```{r}
# first chunks of crops 
draft_crops <- bind_rows(seasonal_crop_prices,
                         nonseasonal_crop_tbl,
                         tea_leaves, 
                         qi_fruit, 
                         cactus_fruit, 
                         grape, 
                         coffee_bean, 
                         wild_plum, 
                         blackberry, 
                         spice_berry, 
                         crystal_fruit) |>
  arrange(item)
```

Lastly, we can add in the category variable and the subcategory variable. to makes things easier, we decided the subcategory would be the crop's season. Then, we write it to a csv in case the website changes or updates.

```{r, warning = FALSE}
# retrieve seasons
seasons <- result[[134]] %>%
  dplyr::select(Season = 1, Crops = 2) |>
  mutate(Crops = strsplit(Crops, " • ", fixed = TRUE)) |>
  unnest(Crops) |>
  mutate(Crops = str_replace_all(Crops, " ", "_"))

# join together seasons and crops
crop_prices <- draft_crops |>
  left_join(seasons, join_by(item == Crops))|>
   mutate(category = "crop",
          sub_category = str_c(Season, " Crop"))|>
  dplyr::select(-Season)

# write csv
#write.csv(crop_prices, "crop_prices.csv")

crop_prices |>
  # kable for nice table in html
  kable() |>
    kable_styling(full_width = FALSE) |>
    scroll_box(width = "100%", height = "200px")
```

### Fish

Fish was the second most difficult item to scrape from the wiki, since again not all of the pages are structured the same. However, we were able identify 4 different pages in which we could write functions to automate.

We start be getting a list of all the different fish in the game.

```{r}
# making sure that this irl is scrapable
fish <- bow("https://stardewvalleywiki.com/Fish", force = TRUE) 

# scraping table to get a list of all the fish 
result <- scrape(fish) |>
  html_nodes(css = "table") |>
  html_table(header = TRUE, fill = TRUE)

# the correct table for the list of fish, and only keeping the names of the fish column
fishes <- result[[224]][2] 

# however, it is formatted very poorly so we need to tidy it up 
fishes <- fishes |>
  mutate(Fish = strsplit(Fish, " • ", fixed = TRUE)) |>
  unnest(Fish) |>
  # splitting the string since " • " was used to separate all fish
  mutate(Fish = str_replace_all(Fish, " ", "_")) |> 
  distinct(Fish) |>
  # this is a fish that is in the data set twice but with different spacing 
  filter(Fish != "_Super_Cucumber") 

# tibble with the subcategories of the fish and the fish name for joining later
subcategory <- result[[224]] |> 
  dplyr::select(Location = 1, Fish = 2) |> 
  mutate(Fish = strsplit(Fish, " • ", fixed = TRUE)) |> 
  unnest(Fish) |>
  mutate(Fish = str_replace_all(Fish, " ", "_"))
```

Create our helper functions for fish:

```{r}
# function for getting the price at a given page and css selector
get_price <- function(page, css_selector) {
  page |>
  html_nodes(css_selector) |>
  html_text()
}

# function for creating a tibble of prices for a given fish this functions output a tibble of our fish and the 4 different prices of the fish dependent on quality

#fish_base_prices takes our fish name,and takes a profession if we specify true or false, as well as the "nthchild_num" value for where the price is being store on that website

fish_base_prices <- function(fish, fisher = FALSE, angler = FALSE, nthchild_num) {
  url <- str_c("https://stardewvalleywiki.com/", fish)
  page <- read_html(url)
  
  qualities <- c("regular", "silver", "gold", "iridium")
  prices <- list()
  
  for (i in seq_along(qualities)) {
    if (fisher) {
      selector <- str_c("tr:nth-child(", nthchild_num,") tr td:nth-child(2) tr:nth-child(", i, ") td+ td")
    } else if (angler) {
      selector <- str_c("tr:nth-child(", nthchild_num,") tr td:nth-child(3) tr:nth-child(", i, ") td+ td")
    } 
    else {
      selector <- str_c("tr:nth-child(", nthchild_num,") tr td:nth-child(1) tr:nth-child(", i, ") td+ td")
    }
    price <- get_price(page, selector)
    prices[[qualities[i]]] <- parse_number(price)
  }
  
  tibble(
    item = fish,
    regular_price = prices$regular,
    silver_price = prices$silver,
    gold_price = prices$gold,
    iridium_price = prices$iridium
  )
}
```

As well as the function for the fish with a different webpage format.
 
```{r}
# this functions output a tibble of our fish and the 2 different prices of the fish dependent on quality

# fish_base_prices takes our fish name, and takes a profession if we specify true or false, as well as the "nthchild_num" value for where the price is being store on that website

fish_base_prices2 <- function(fish, fisher = FALSE, angler = FALSE, nthchild_num) {
  url <- str_c("https://stardewvalleywiki.com/", fish)
  page <- read_html(url)
  
  qualities <- c("regular", "silver", "gold", "iridium")
  prices <- list()
  
  for (i in seq_along(qualities)) {
    if (fisher) {
      selector <- str_c("tr:nth-child(", nthchild_num,") tr td:nth-child(2) tr:nth-child(", i, ") td+ td")
    } else if (angler) {
      selector <- str_c("tr:nth-child(", nthchild_num,") tr td:nth-child(3) tr:nth-child(", i, ") td+ td")
    } 
    else {
      selector <- str_c("tr:nth-child(", nthchild_num,") tr td:nth-child(1) tr:nth-child(", i, ") td+ td")
    }
    price <- get_price(page, selector)
    prices[[qualities[i]]] <- parse_number(price)
  }
  
  tibble(
    item = fish,
    regular_price = prices$regular,
    silver_price = prices$silver,
  )
}
```

Now, we will load in our fishes lists so for the type of webpage format they have and then apply our function to the fishes to find their prices.

```{r, echo = FALSE}
# list of our fishes tibble to view, then dividing up the fish by their website format
fishes_list <- pull(fishes) 

# loading in the fish we know that are tr:nth-child(14) in the html (these fishes were found in the Fish QMD when first exploring and getting to know our website)
fishfor14 <- readRDS("fishfor14.RDS")
fishfor14

# loading in the fish we know that are tr:nth-child(15) in the html, same as above
fishfor15 <- readRDS("fishfor15.RDS")
fishfor15

# loading in the fish we know that are tr:nth-child(10) in the html, same as above
fishfor10 <- readRDS("fishfor10.RDS")
fishfor10 

# loading in the fish we know that are tr:nth-child(10) in the html, same as above
fishleft <- readRDS("fishleft.RDS")
fishleft
```


```{r}
# creating list of tbl's to store prices so that we can bind into one big tibble
fish_prices <- vector("list", length = 12)

# base prices without profession for tr:nth-child(14)
fish_prices[[1]] <- fishfor14 |>
  purrr::map_dfr(~ fish_base_prices(.x, nthchild_num = 14)) |>
  mutate(profession = as.character(NA))

# prices with Fisher profession
fish_prices[[2]] <- fishfor14 |>
  purrr::map_dfr(~ fish_base_prices(.x, fisher = TRUE, nthchild_num = 14)) |>
  mutate(profession = "fisher")

# prices with Angler profession
fish_prices[[3]] <- fishfor14 |>
  purrr::map_dfr(~ fish_base_prices(.x, angler = TRUE, nthchild_num = 14)) |>
  mutate(profession = "angler")

# base prices without profession for tr:nth-child(15)
fish_prices[[4]] <- fishfor15 |>
  purrr::map_dfr(~ fish_base_prices(.x, nthchild_num = 15)) |>
  mutate(profession = as.character(NA))

# prices with Fisher profession
fish_prices[[5]] <- fishfor15 |>
  purrr::map_dfr(~ fish_base_prices(.x, fisher = TRUE, nthchild_num = 15)) |>
  mutate(profession = "fisher")

# prices with Angler profession
fish_prices[[6]] <- fishfor15 |>
  purrr::map_dfr(~ fish_base_prices(.x, angler = TRUE, nthchild_num = 15)) |>
  mutate(profession = "angler")

# base prices without profession for tr:nth-child(10)
fish_prices[[7]] <- fishfor10 |>
  purrr::map_dfr(~ fish_base_prices(.x, nthchild_num = 10)) |>
  mutate(profession = as.character(NA))

# prices with Fisher profession
fish_prices[[8]] <- fishfor10 |>
  purrr::map_dfr(~ fish_base_prices(.x, fisher = TRUE, nthchild_num = 10)) |>
  mutate(profession = "fisher")

# prices with Angler profession
fish_prices[[9]] <- fishfor10 |>
  purrr::map_dfr(~ fish_base_prices(.x, angler = TRUE, nthchild_num = 10)) |>
  mutate(profession = "angler")

# base prices without profession for tr:nth-child(10) but only two qualities
fish_prices[[10]] <- fishleft |>
  purrr::map_dfr(~ fish_base_prices2(.x, nthchild_num = 10)) |>
  mutate(profession = as.character(NA))

# prices with Fisher profession
fish_prices[[11]] <- fishleft |>
  purrr::map_dfr(~ fish_base_prices2(.x, fisher = TRUE, nthchild_num = 10)) |>
  mutate(profession = "fisher")

# prices with Angler profession
fish_prices[[12]] <- fishleft |>
  purrr::map_dfr(~ fish_base_prices2(.x, angler = TRUE, nthchild_num = 10)) |>
  mutate(profession = "angler")
```

Finally we will take our fish prices and then create one big tibble.

```{r, warning = FALSE}
# first tbl in fish prices assigned to our final tibble 
tidy_fish_prices <- fish_prices[[1]] 

# for loop for iterating each tbl in our fish prices list to our final tibble
for (i in 2:12){
  tidy_fish_prices <- bind_rows(tidy_fish_prices, fish_prices[[i]])
}

# viewing and alphabetizing our tidy fish tbl also joining our subcategories and assigning category
tidy_fish_prices <- tidy_fish_prices |>
  left_join(subcategory, join_by(item == Fish)) |>
  mutate(category = "fish") |>
  rename(sub_category = Location) |>
  arrange(item)

# writing our tbl as a csv so that we can join with the other items 
#write.csv(tidy_fish_prices, "fish_prices.csv")

tidy_fish_prices |>
  # kable for nice table in html
  kable() |>
    kable_styling(full_width = FALSE) |>
    scroll_box(width = "100%", height = "200px")
```

### Animal Products

Animal products was one of the easier items to scrape since we were able to scrape the data from a table.

```{r}
#first be polite and check that we can scrape it 
robotstxt::paths_allowed("https://stardewvalleywiki.com/Animal_Products_Profitability")

session <- bow("https://stardewvalleywiki.com/Animal_Products_Profitability", force = TRUE)

#take the second table, because that is the one we are interested in
result_animals <- scrape(session) |>
  html_nodes(css = "table") |> 
  html_table(header = TRUE, fill = TRUE)

sd_animal_prices <- result_animals[[2]]
```

After scraping, all all we have to do is clean up our tibble since it isn't in the format we want it to be to join with the rest of our items.

```{r}
#clean up the sd_animal_prices tibble
tidy_sd_animal_price <- sd_animal_prices |>
  clean_names()|>
  dplyr::select(item, 
         profession, 
         quality, 
         sell_price) |> #select only the columns we want
  group_by(item, profession)|>
  pivot_wider(names_from = quality, 
              values_from = sell_price, 
              names_glue = "{quality}_price",
              values_fn = mean)|>
  clean_names()|>
  mutate(category = "animal product",
         profession = ifelse(profession == "—", NA, profession))

#write the final version to a csv
#write.csv(tidy_sd_animal_price, "animal_product_prices.csv")

tidy_sd_animal_price |>
  # kable for nice table in html
  kable() |>
    kable_styling(full_width = FALSE) |>
    scroll_box(width = "100%", height = "200px")
```

### Minerals

Minerals was one of the easier items to scrape since we were able to scrape the data from a table. However assigning the category and subcategories is what made the process a little more tedious.  

```{r}
# first be polite and check that we can scrape it 
robotstxt::paths_allowed("https://stardewvalleywiki.com/Minerals")

session <- bow("https://stardewvalleywiki.com/Minerals", force = TRUE)

result_minerals <- scrape(session) |>
  html_nodes(css = "table") |> 
  html_table(header = TRUE, fill = TRUE)
# interested in tables 1-4
```

Again, after collecting our data, all we have to do is clean it up to join with our other categories. 

```{r}
# this function takes a scraped minerals table and preps it for joining with other datasets
tidy_minerals <- function(data, sub_cat){
  data|>
  clean_names()|>
  mutate(item = name,
         category = "mineral",
         sub_category = sub_cat)|>
  rename(regular_sell_price = sell_price)|>
  pivot_longer(
    cols = c(gemologist_sell_price,
             regular_sell_price),
    names_to = "profession",
    values_to = "sell_price"
  )|>
  dplyr::select(item, 
         profession, 
         sell_price,
         category,
         sub_category)|>
  mutate(sell_price = as.numeric(str_extract(sell_price, '(?<=data-sort-value=")\\d+')),
         profession = ifelse(profession == "gemologist_sell_price",
                             "gemologist", NA))
  
 
}

# use function for the 1-3 tables using a for loop
minerals_tbl <- vector("list", length = 4)
mineral_sub_cat <- c("foraged mineral",
                     "gem",
                     "geode mineral",
                     "geode")
for (i in 1:3){
  minerals_tbl[[i]] <- tidy_minerals(result_minerals[[i]], mineral_sub_cat[i])
  
}

# clean up the variable names so that it is ready for the row bind.
# make sure the category is all mineral, and the sub_category is correct
minerals_tbl[[4]]<- result_minerals[[4]]|>
  clean_names()|>
  mutate(item = name,
         category = "mineral",
         sub_category = "geode",
         sell_price = as.numeric(str_extract(sell_price, '(?<=data-sort-value=")\\d+')),
         profession = NA)|>
  dplyr::select(item, sell_price, category, sub_category, profession)

tidy_sd_minerals_price <- bind_rows(minerals_tbl)
```

Now writing minerals to a csv just in case the website changes or updates.

```{r}
#write.csv(tidy_sd_minerals_price, "minerals_prices.csv")

tidy_sd_minerals_price |>
  # kable for nice table in html
  kable() |>
    kable_styling(full_width = FALSE) |>
    scroll_box(width = "100%", height = "200px")
```

#### Combined Dataset

We then merge together all of the data sets for each of the 4 categories: crops, fish, animal products, and minerals.

```{r}
# binding rows for all of different categories 
stardew_items <- bind_rows(crop_prices, 
                           tidy_sd_animal_price, 
                           tidy_sd_minerals_price,
                           tidy_fish_prices)

#write.csv(stardew_items, "stardew_items.csv")

stardew_items |>
  # kable for nice table in html
  kable() |>
    kable_styling(full_width = FALSE) |>
    scroll_box(width = "100%", height = "200px")
```

## Additional Data

### Seeds

While working on our shiny app we realized that we needed additional data for crops involving the seed data for the crop because it consisted of growth time which is how long the crop takes to grow. 

```{r}
# make sure can scrape
seed <- bow("https://stardewvalleywiki.com/Potato_Seeds", force = TRUE)

result <- scrape(seed) |>
  html_nodes(css = "table") |>
  html_table(header = TRUE, fill = TRUE)

seeds <- result[[4]][2] #table of the seeds so we can use that list

seeds <- seeds |>
  mutate(Seed = strsplit(`Seeds, Starters, and Saplings`, " • ", fixed = TRUE)) |>
  unnest(Seed) |>
  mutate(Seed = str_replace_all(Seed, " ", "_")) |>
  distinct(Seed) |>
  filter(Seed != "Coffee_Beans")
```

Like our other categories we created a function to scrape the seed data. 

```{r, warning = FALSE}
get_growth <- function(page, css_selector) {
  page |>
  html_nodes(css_selector) |>
  html_text()
}

# function for growth time
seeddeets <- function(seed) {
  url <- str_c("https://stardewvalleywiki.com/", seed)
    page <- read_html(url)
    growth_time <- get_growth(page, "tr:nth-child(6) #infoboxdetail")
    general_store <- get_growth(page, "tr:nth-child(10) #infoboxdetail .no-wrap")
    jojamart <- get_growth(page, "tr:nth-child(11) #infoboxdetail .no-wrap")
    oasis <- get_growth(page, "tr:nth-child(12) #infoboxdetail , .no-wrap+ #infoboxdetail .no-wrap")
    item <- seed
    
    seedinfo_tbl <- tibble(
      item = item,
      growth_time = parse_number(growth_time),
      general_store = parse_number(general_store), 
      jojamart = parse_number(jojamart),
      #oasis = parse_number(oasis)
    )
}

# list of all seeds
seeds_list <- as.vector(seeds$Seed)

details <- purrr::map(seeds_list, seeddeets)

draft_seed <- bind_rows(details) |>
  arrange(item)

# check which seeds didn't work
empty_indices <- which(sapply(details, function(tbl) nrow(tbl) == 0))

# assign to list
seeds_needed <- seeds_list[empty_indices]
```

Another function for the seeds needed from above.

```{r, warning = FALSE}
# function for growth time
seeddeets2 <- function(seed) {
  url <- str_c("https://stardewvalleywiki.com/", seed)
    page <- read_html(url)
    growth_time <- get_growth(page, "tr:nth-child(6) #infoboxdetail")
    general_store <- get_growth(page, "tr:nth-child(10) #infoboxdetail")
    jojamart <- get_growth(page, "tr:nth-child(11) #infoboxdetail")
    item <- seed
    
    seedinfo_tbl <- tibble(
      item = item,
      growth_time = parse_number(growth_time),
      general_store = parse_number(str_extract(general_store, "[0-9]+")), 
      jojamart = parse_number(jojamart)
      )}

details2 <- purrr::map(seeds_needed, seeddeets2)

draft_seed2 <- bind_rows(details2) |>
  arrange(item)

empty_indices2 <- which(sapply(details2, function(tbl) nrow(tbl) == 0))

# seeds needed again
seeds_needed2 <- seeds_needed[empty_indices2]

#bind together rows since no more seeds needed
seed_details <- bind_rows(details, details2) |>
  arrange(item)
```

After collecting all the information we found that we weren't able to just join the crops dataset with our seed details since the names are very off, for example we aren't able to join Amarath_Seeds with Amarath since it has the seeds at the end or Apples with Apple_Saplings, or Pepper_Seeds with Hot_Pepper, so we had to manually look at our data and string replace lots of items that would've ended up lost in the join. 

```{r}
# manually change names so we can join together with crops later.
seed_deets <- seed_details |>
  mutate(item = str_replace(item, "_Seeds?", ""),
         item = str_replace(item, "_Saplings?", ""),
         item = str_replace(item, "_Bulb", ""),
         item = str_replace(item, "_Starter", ""),
         item = str_replace(item, "_Shoots?", ""),
         item = str_replace(item, "_Tuber", ""),
         item = str_replace(item, "_Bean", "_Fruit"),
         item = str_replace(item, "Cactus", "Cactus_Fruit"),
         item = str_replace(item, "Fairy", "Fairy_Rose"),
         item = str_replace(item, "Jazz", "Blue_Jazz"),
         item = str_replace(item, "Tea", "Tea_Leaves"),
         item = str_replace(item, "Taro", "Taro_Root"),
         item = str_replace(item, "Spangle", "Summer_Spangle"),
         item = str_replace(item, "Rare", "Sweet_Gem_Berry"),
         item = str_replace(item, "Bean", "Green_Bean"),
         item = str_replace(item, "Ancient", "Ancient_Fruit"),
         item = str_replace(item, "Pepper", "Hot_Pepper"),
         item = str_replace(item, "Rice", "Unmilled_Rice"))

oasis <- data.frame(
    item = c("Cactus_Fruit", "Rhubarb", "Starfruit", "Beet"),
    oasis_price = c(150, 100, 400, 20)
  )

seed_deets <- seed_deets|>
  left_join(oasis, join_by(item))

#write.csv(seed_deets, "seed_deets.csv")

seed_deets |>
  # kable for nice table in html
  kable() |>
    kable_styling(full_width = FALSE) |>
    scroll_box(width = "100%", height = "200px")
  
```

### Animal Origins

We also wanted the origins of where a product came, this took two steps, first scraping the animal products table and then joining it with another table, we also set the profession instead of NA to be none and did not pivot it for future use in our app. 

```{r}
animaltable <- bow("https://stardewvalleywiki.com/Animal_Products_Profitability", force = TRUE)

result <- scrape(animaltable) |>
  html_nodes(css = "table") |>
  html_table(header = TRUE, fill = TRUE)

animal_table <- result[[2]] 

animal_table <- animal_table |>
  clean_names() |>
  mutate(profession = ifelse(profession == "—", "none", profession)) |>
  filter(profession != "Treasure Appraisal Guide and  Artisan")

animal_table |>
  # kable for nice table in html
  kable() |>
    kable_styling(full_width = FALSE) |>
    scroll_box(width = "100%", height = "200px")
```

This data below was collected from another table and then intensely formatted with string functions so that we could then join the animal to the product it produced. 

```{r}
animalasso <- bow("https://stardewvalleywiki.com/Animals", force = TRUE)

result <- scrape(animalasso) |>
  html_nodes(css = "table") |>
  html_table(header = TRUE, fill = TRUE)

animal_asso <- result[[14]][2]

animal_n_items <- animal_asso |>
  clean_names() |>
  mutate(animals_and_produce = strsplit(animals_and_produce, ") • ", fixed = TRUE)) |>
  unnest(animals_and_produce) |>
  filter(row_number() != 14) |>
  mutate(animal = str_extract(animals_and_produce, "^[^(]+"),
         product = str_extract(animals_and_produce, "\\(.*")) |>
  dplyr::select(animal, product) |>
  mutate(animal = str_replace(animal, " ", "_"),
         animal = str_replace(animal, " ", ""),
         animal = str_replace(animal, "_$", ""),
         product = str_replace(product, "\\(", ""),
         product = str_replace(product, "\\)", ""),
         product = strsplit(product, " • ", fixed = TRUE)) |>
  unnest(product)

full_animal_table <- animal_table |>
  left_join(animal_n_items, join_by(item == product), relationship =
  "many-to-many")

#write_csv(full_animal_table, "full_animal_table.csv")

full_animal_table |>
  # kable for nice table in html
  kable() |>
    kable_styling(full_width = FALSE) |>
    scroll_box(width = "100%", height = "200px")
```

### Wrangling:

#### Crops

Additional wrangling had to be done because our app wouldn't work if there were NA values, so instead of NA values for if an item wasn't sold at a store we set the values to zero. However, we first worked with our crops dataset, we needed to join the grow times and add more information. 

```{r, warning = FALSE}
# zero out everything with crop prices and create crop prices2
crop_prices2 <- crop_prices |>
  left_join(seed_deets, join_by(item)) |>
  mutate(profession = replace_na(profession, "none"),
         sub_category = replace_na(sub_category, "Special Crop"),
         growth_time = replace_na(growth_time, 0),
         general_store = replace_na(general_store, 0),
         jojamart = replace_na(jojamart, 0),
         oasis_price = replace_na(oasis_price, 0)) |>
  filter(!item %in% c("Qi_Fruit", "Tea_Leaves"))

#write.csv(crop_prices2, "crop_prices2.csv")
```

An issue we ran into was that some plants drop multiple crops when harvested so for calculating the profit we had to take that into account as well. For those specific crops we made a new data frame and specified how many crops they drop. Another issue was that some plants can regrow, so you only have to buy the seed and plant the seed once in a season so planting these early on so that they can continue produce crops throughout the season. After finally accounting for these things we are able to join our data together and ultimately create a gold per day column for each quality of crop.  

```{r, warning = FALSE}
regrow <- as.data.frame(
  list(item = c("Ancient Fruit", "Blueberry", "Broccoli", "Cactus Fruit", "Coffee Bean",
             "Corn", "Cranberries", "Eggplant", "Grape", "Green Bean", "Hops", "Hot Pepper",
             "Pineapple", "Strawberry", "Summer Squash", "Tea Leaves", "Tomato"),
    crops_per_harvest = c(1, 3, 1, 1, 4, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)))

regrow <- regrow|>
  mutate(can_regrow = "TRUE")
  
crop_prices3 <- crop_prices2 |>
  mutate(
    season = str_replace(sub_category, " Crop", ""),
    seed_price = ifelse(general_store != 0, 
                        general_store, 
                        ifelse(oasis_price != 0, oasis_price, 0)),
    seed_price = ifelse(item == "Strawberry", 100, seed_price)
  ) |>
  left_join(regrow, join_by(item)) |>
  mutate(
    crops_per_harvest = ifelse(is.na(crops_per_harvest), 1, crops_per_harvest),
    can_regrow = ifelse(is.na(can_regrow), FALSE, TRUE)
  ) |>
  mutate(
    regular_gold_per_day = round(((regular_price * crops_per_harvest) - seed_price) / growth_time, 3),
    silver_gold_per_day = round(((silver_price * crops_per_harvest) - seed_price) / growth_time, 3),
    gold_gold_per_day = round(((gold_price * crops_per_harvest) - seed_price) / growth_time, 3),
    iridium_gold_per_day = round(((iridium_price * crops_per_harvest) - seed_price) / growth_time, 3)
  )

#write.csv(crop_prices3, "final_crop_prices.csv")

crop_prices3 |>
  # kable for nice table in html
  kable() |>
    kable_styling(full_width = FALSE) |>
    scroll_box(width = "100%", height = "200px")
```

#### NA Professions

Similar to the NA values for if the seed wasn't sold at the mart, our app wouldn't run if there were NA values for the profession, so for every category we will update the NA value with "none"

```{r}
final_minerals_prices <- tidy_sd_minerals_price |>
  mutate(profession = replace_na(profession, "none"))
#write_csv(final_minerals_prices, "final_minerals_prices.csv")

fish_prices <- tidy_fish_prices |>
  mutate(profession = replace_na(profession, "none"))
#write_csv(fish_prices, "fish_prices.csv")
```

### Fish Map

Lastly, we need the data for creating our map for the locations of the fish. 

```{r, warning = FALSE}
line_thick = 0.05
width = 1224
height = 742

# Draw a rectangle that defines the shape of map
map_int <- rbind(
  c(0, 0),
  c(0, height),
  c(width, height),
  c(width, 0),
  c(0,0)
  )

# Draw a rectangle that defines the map exterior
map_ext <- rbind(
  c(0-line_thick, 0-line_thick),
  c(0-line_thick, height + line_thick),
  c(width + line_thick, height + line_thick),
  c(width + line_thick, 0-line_thick),
  c(0-line_thick, 0-line_thick)
  )

# Define a sfg polygon object in sf by subtracting interior from exterior
map_shape <- st_polygon(list(map_ext, map_int))

# verify sfg class of polygon
#class(map_shape)

# save shapefile as rds
#saveRDS(map_shape, "projects/archived_folder/stardew_data_folder/map_shape.rds")

# load the image as a raster
#img <- brick("projects/archived_folder/stardew_data_folder/stardewmap.png") 

# inspect the image dimensions
#print(img)

# extract bounds (xmin, xmax, ymin, ymax)
#bounds <- extent(img)
#print(bounds)

# create image map df with center map pixel size
stardewmap_df <- data.frame(
  x = 612, 
  y = 371, 
  image = "stardewmap.png"
)

# write it in csv form 
#write_csv(stardewmap_df, "projects/archived_folder/stardew_data_folder/stardewmap_df.csv")
#stardewmap_df <-read_csv("projects/archived_folder/stardew_data_folder/stardewmap_df.csv")

# testing map
ggplot() +
  geom_sf(data = map_shape) +
  geom_image(data = stardewmap_df, aes(x, y, image = image), size = 1.496)
```

Now that we have our map, we want to specify the x and y coodinates of our location, we did this by creating a new data frame with these locations. 

```{r}
# get data ready
xy <- data.frame(
    sub_category = c("The Beach", "River", "Night Market", "Ginger Island", "Mountain Lake", "Secret Woods", "Sewers", "Mutant Bug Lair", "Witch's Swamp", "Crab Pot", "Mines", "Cindersap Forest Pond", "Desert"),
    x = c(850, 850, 800, 1150, 900, 200, 725, 725, 210, 400, 900, 300, 20),
    y = c(120, 300, 100, 50, 550, 400, 260, 260, 305, 390, 610, 300, 710)
  )

# write in our x and y coordinates
#write_csv(xy, "projects/archived_folder/stardew_data_folder/xy.csv")
#read_csv("projects/archived_folder/stardew_data_folder/xy.csv")

fish_prices_sf <- fish_prices |>
  left_join(xy, join_by(sub_category)) |>
  filter(!is.na(x)) |>
  mutate(x = ifelse(item == "Angler", 815, x),
         y = ifelse(item == "Angler", 500, y),
         x = ifelse(item == "Ms._Angler", 815, x),
         y = ifelse(item == "Ms._Angler", 500, y),
         x = ifelse(item == "Crimson", 805, x),
         y = ifelse(item == "Crimson", 70, y),
         x = ifelse(item == "Son_of_Crimsonfish", 805, x),
         y = ifelse(item == "Son_of_Crimsonfish", 70, y),
         ) |>  
  st_as_sf(coords = c("x", "y"))

# save shapefile
#saveRDS(fish_prices_sf, "projects/archived_folder/stardew_data_folder/fish_prices_sf.rds")
#fish_prices_sf <- readRDS("data/fish_prices_sf.rds")
```

Finally, we have all the information needed to make our app work. 
